{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "# import gffutils\n",
    "import time\n",
    "# import pybedtools\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "from multiprocessing import Pool\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_file_name = \"Homo_sapiens.GRCh38.112.chr.gtf\"\n",
    "# gtf_file_name = \"/home/U210050044/data/DH607-project/Homo_sapiens.GRCh38.112.chr.gtf\"\n",
    "# sql_db_name = \"db-human.sqlite3\"\n",
    "sql_db_name = \"file:gtf?mode=memory&cache=shared\"\n",
    "results_file_name = \"results_human.txt\"\n",
    "lib = ctypes.CDLL(\"./gtf_to_sql.so\")\n",
    "# Define the function signature\n",
    "lib.run_gtf_to_sql.argtypes = [\n",
    "    ctypes.c_char_p,  # db_name\n",
    "    ctypes.c_char_p,  # table_name\n",
    "    ctypes.c_char_p,  # input_file\n",
    "    ctypes.c_int,     # num_threads\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open(results_file_name,\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading into pyranges object in time 128.64200735092163\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "human_gr = pr.read_gtf(gtf_file_name)\n",
    "end_time = time.time()\n",
    "results_file.write(f\"Finished reading into pyranges object in time {end_time-start_time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting gtf to sql db in time 460.73711919784546\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "# human_db = gffutils.create_db(\"/home/U210050044/data/DH607-project/Homo_sapiens.GRCh38.112.chr.gtf\",\"/home/U210050044/data/DH607-project/human_db.sqlite3\",disable_infer_genes=True,disable_infer_transcripts=True, force=True)\n",
    "# end_time = time.time()\n",
    "# results_file.write(f\"Finished converting gtf to sql db in time {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the database\n",
    "# human_db = gffutils.FeatureDB(\"/home/U210050044/data/DH607-project/human_db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading into sql db in time 74.16784691810608\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "os.system(\"g++ -std=c++11 -shared -fPIC -o gtf_to_sql.so gtf_to_sql.cpp -lsqlite3 -pthread\")\n",
    "start_time = time.time()\n",
    "lib.run_gtf_to_sql(sql_db_name.encode(\"utf-8\"), \"human\".encode(\"utf-8\"), gtf_file_name.encode(\"utf-8\"), 8)\n",
    "end_time = time.time()\n",
    "results_file.write(f\"Finished reading into sql db in time {end_time-start_time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(sql_db_name)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading from sql to pyranges in time 70.34932708740234\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "human_gr2 = pr.PyRanges(pd.read_sql(\"SELECT * FROM human\", conn))\n",
    "end_time = time.time()\n",
    "results_file.write(f\"Finished reading from sql to pyranges in time {end_time-start_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Queries: Counting transcripts, calculating exon lengths, and grouping features\n",
    "### Aggregate Query 1: Count the number of exons for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 s ± 989 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time taken to count exons using pyranges is 12 s ± 989 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Using pyranges\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o (human_gr[human_gr.Feature == \"exon\"].df.groupby(\"gene_id\").size().reset_index(name=\"exon_count\"))')\n",
    "results_file.write(f\"Time taken to count exons using pyranges is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 s ± 32.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # Using gffutils\n",
    "# def exon_counts_gffutls():\n",
    "#     # Iterate over all genes and count their exons\n",
    "#     exon_counts = {}\n",
    "#     for gene in human_db.features_of_type(\"gene\"):\n",
    "#         # Efficiently count exons for each gene using the `children` method\n",
    "#         exon_counts[gene.id] = sum(\n",
    "#             1 for _ in human_db.children(gene, featuretype=\"exon\")\n",
    "#     )\n",
    "#     return exon_counts\n",
    "# %timeit exon_counts_gff = exon_counts_gffutls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38 s ± 133 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Using sql\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o exon_counts_sql = pd.read_sql_query(\"SELECT gene_id, COUNT(*) as exon_count FROM human WHERE Feature = \\'exon\\' GROUP BY gene_id\", conn)')\n",
    "results_file.write(f\"Time taken to count exons using sql is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if exon_counts_pr and exon_counts_sql are identical\n",
    "exon_counts_pr = (human_gr[human_gr.Feature == \"exon\"].df.groupby(\"gene_id\").size().reset_index(name=\"exon_count\"))\n",
    "exon_counts_sql = pd.read_sql_query(\"SELECT gene_id, COUNT(*) as exon_count FROM human WHERE Feature = 'exon' GROUP BY gene_id\", conn)\n",
    "exon_counts_sql[\"exon_count\"] = exon_counts_sql[\"exon_count\"].astype(int)\n",
    "exon_counts_pr[\"exon_count\"] = exon_counts_pr[\"exon_count\"].astype(int)\n",
    "if exon_counts_sql.equals(exon_counts_pr):\n",
    "    results_file.write(\"exon counts are identical\\n\")\n",
    "else:\n",
    "    results_file.write(\"exon counts are not identical\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Query 2: Calculate the total length of exons for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.77 s ± 56.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Using pyranges\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o exon_lengths_pr = (human_gr[human_gr.Feature == \"exon\"].df.assign(length=lambda df: df[\"End\"] - df[\"Start\"]).groupby(\"gene_id\")[\"length\"].sum().reset_index(name=\"total_exon_length\"))')\n",
    "results_file.write(f\"Time taken to calculate total exon length using pyranges is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.8 s ± 80.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # Using gffutils\n",
    "# def exon_lengths_gffutls():\n",
    "#     # Dictionary to store total exon length per gene\n",
    "#     exon_lengths = {}\n",
    "#     # Iterate over all genes and calculate total exon length\n",
    "#     for gene in human_db.features_of_type(\"gene\"):\n",
    "#         # Compute total exon length for each gene\n",
    "#         exon_lengths[gene.id] = sum(\n",
    "#             (child.end - child.start + 1)\n",
    "#             for child in human_db.children(gene, featuretype=\"exon\")\n",
    "#         )\n",
    "#     return exon_lengths\n",
    "# %timeit exon_lengths_gff = exon_lengths_gffutls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 s ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using sql\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o exon_lengths_sql = pd.read_sql_query(\"SELECT gene_id, SUM(End - Start) as total_exon_length FROM human WHERE Feature = \\'exon\\' GROUP BY gene_id\", conn)')\n",
    "results_file.write(f\"Time taken to calculate total exon length using sql is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if exon_lengths_pr and exon_lengths_sql are identical\n",
    "exon_lengths_pr = (human_gr[human_gr.Feature == \"exon\"].df.assign(length=lambda df: df[\"End\"] - df[\"Start\"]).groupby(\"gene_id\")[\"length\"].sum().reset_index(name=\"total_exon_length\"))\n",
    "exon_lengths_sql = pd.read_sql_query(\"SELECT gene_id, SUM(End - Start) as total_exon_length FROM human WHERE Feature = 'exon' GROUP BY gene_id\", conn)\n",
    "exon_lengths_sql[\"total_exon_length\"] = exon_lengths_sql[\"total_exon_length\"].astype(int)\n",
    "exon_lengths_pr[\"total_exon_length\"] = exon_lengths_pr[\"total_exon_length\"].astype(int)\n",
    "if exon_lengths_sql.equals(exon_lengths_pr):\n",
    "    results_file.write(\"exon lengths are identical\\n\")\n",
    "else:\n",
    "    results_file.write(\"exon lengths are not identical\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Query 3: Identify the chromosome with the highest number of transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953 ms ± 23.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Using pyranges\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o transcript_counts_pr = human_gr[human_gr.Feature == \"transcript\"].df[\"Chromosome\"].value_counts().idxmax()')\n",
    "results_file.write(f\"Time taken to find chromosome with most transcripts using pyranges is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.52 s ± 31.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # Using gffutils\n",
    "# def transcript_counts_gffutls():\n",
    "#     # Dictionary to store the number of transcripts per chromosome\n",
    "#     transcript_counts = {}\n",
    "#     # Iterate over all transcripts and count the number of transcripts per chromosome\n",
    "#     for transcript in human_db.features_of_type(\"transcript\"):\n",
    "#         chrom = transcript.chrom\n",
    "#         if chrom not in transcript_counts:\n",
    "#             transcript_counts[chrom] = 0\n",
    "#         transcript_counts[chrom] += 1\n",
    "#     return max(transcript_counts, key=transcript_counts.get)\n",
    "# %timeit transcript_counts_gff = transcript_counts_gffutls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531 ms ± 2.61 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using sql\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o transcript_counts_sql = pd.read_sql_query(\"SELECT Chromosome, COUNT(*) as transcript_count FROM human WHERE Feature = \\'transcript\\' GROUP BY Chromosome ORDER BY transcript_count DESC LIMIT 1\", conn)')\n",
    "results_file.write(f\"Time taken to find chromosome with most transcripts using sql is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify if transcript_counts_pr and transcript_counts_sql are identical\n",
    "transcript_counts_pr = human_gr2[human_gr2.Feature == \"transcript\"].df[\"Chromosome\"].value_counts().idxmax()\n",
    "transcript_counts_sql = pd.read_sql_query(\"SELECT Chromosome, COUNT(*) as transcript_count FROM human WHERE Feature = 'transcript' GROUP BY Chromosome ORDER BY transcript_count DESC LIMIT 1\", conn)\n",
    "if transcript_counts_pr == transcript_counts_sql[\"Chromosome\"].values[0]:\n",
    "    results_file.write(\"transcript counts are identical\\n\")\n",
    "else:\n",
    "    results_file.write(\"transcript counts are not identical\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interval Arithmetic\n",
    "### Query 1: Merging Overlapping Exon Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.48 s ± 383 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time taken to merge exons using pyranges is 5.48 s ± 383 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Using pyranges\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o exon_intervals_pr = human_gr[human_gr.Feature == \"exon\"].merge(strand=True)')\n",
    "results_file.write(f\"Time taken to merge exons using pyranges is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using gffutils TODO: run\n",
    "# def exon_intervals_gffutls():\n",
    "#     exon_intervals = [\n",
    "#         gffutils.helpers.asinterval(exon) for exon in human_db.features_of_type(\"exon\")\n",
    "#     ]\n",
    "#     exon_intervals_sorted = sorted(exon_intervals, key=lambda x: (x.chrom, x.start))\n",
    "#     # Use pybedtools to merge overlapping intervals\n",
    "#     return pybedtools.BedTool(exon_intervals_sorted).merge()\n",
    "# %timeit exon_intervals_gff = exon_intervals_gffutls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sql\n",
    "def get_exon_intervals_sql(chrom_strand):\n",
    "    chrom, strand = chrom_strand\n",
    "    exon_intervals_sql = pd.read_sql_query(f\"SELECT Start, End FROM human WHERE Feature = 'exon' AND Chromosome = '{chrom}' AND Strand = '{strand}'\", conn)\n",
    "    exon_intervals_sql = pr.methods.merge._merge(exon_intervals_sql, chromosome=chrom, count=None, strand=strand)\n",
    "    return exon_intervals_sql\n",
    "\n",
    "def get_exon_intervals_sql_multi():\n",
    "    chrom_strand_tup = pd.read_sql_query(\"SELECT DISTINCT Chromosome, Strand FROM human\", conn)\n",
    "    chrom_strand_tup = list(zip(chrom_strand_tup[\"Chromosome\"], chrom_strand_tup[\"Strand\"]))\n",
    "    with Pool(8) as p:\n",
    "        exon_intervals_sql = p.map(get_exon_intervals_sql, chrom_strand_tup)\n",
    "    exon_intervals_sql = pd.concat(exon_intervals_sql).sort_values([\"Chromosome\", \"Strand\", \"Start\", \"End\"]).reset_index(drop=True)\n",
    "    return exon_intervals_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.07 s ± 101 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time taken to merge exons using sql is 4.07 s ± 101 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "time = get_ipython().run_line_magic(\"timeit\",'-o exon_intervals_sql = get_exon_intervals_sql_multi()')\n",
    "results_file.write(f\"Time taken to merge exons using sql is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exon intervals are identical\n"
     ]
    }
   ],
   "source": [
    "# check if exon_intervals_pr and exon_intervals_sql are identical\n",
    "exon_intervals_pr = human_gr[human_gr.Feature == \"exon\"].merge(strand=True).df.sort_values([\"Chromosome\", \"Strand\", \"Start\", \"End\"]).reset_index(drop=True)\n",
    "exon_intervals_sql = get_exon_intervals_sql_multi()\n",
    "if exon_intervals_pr.equals(exon_intervals_sql):\n",
    "    results_file.write(\"exon intervals are identical\\n\")\n",
    "else:\n",
    "    results_file.write(\"exon intervals are not identical\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Finding Overlaps with a Specific Interval\n",
    "Find all gene features that overlap a given interval chr1:100000-200000 + strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 s ± 42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time taken to find overlapping genes using pyranges is 1.03 s ± 42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Using pyranges\n",
    "time = get_ipython().run_line_magic(\"timeit\",'-o overlapping_genes_pr = human_gr[human_gr.Feature == \"gene\"].overlap(pr.from_dict({\"Chromosome\": [\"1\"], \"Start\": [100000], \"End\": [200000], \"Strand\": [\"+\"]}), strandedness=\"same\")')\n",
    "results_file.write(f\"Time taken to find overlapping genes using pyranges is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 29s ± 414 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # using gffutils TODO: run\n",
    "# def overlapping_genes_gffutls():\n",
    "#     exon_intervals_overlapping = pybedtools.BedTool.from_dataframe(pd.DataFrame({\"Chromosome\": [\"1\"], \"Start\": [100000], \"End\": [200000]}))\n",
    "#     exon_intervals = [\n",
    "#         gffutils.helpers.asinterval(exon) for exon in human_db.features_of_type(\"exon\")\n",
    "#     ]\n",
    "#     exon_intervals_sorted = sorted(exon_intervals, key=lambda x: (x.chrom, x.start))\n",
    "#     # Use pybedtools to merge overlapping intervals\n",
    "#     return exon_intervals_overlapping.window(pybedtools.BedTool(exon_intervals_sorted).merge(), w=0)\n",
    "# %timeit overlapping_genes_gff = overlapping_genes_gffutls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sql\n",
    "other_genes_all = pd.DataFrame({\"Chromosome\": [\"1\"], \"Start\": [100000], \"End\": [200000], \"Strand\": [\"+\"]})\n",
    "def get_overlapping_genes_sql(chrom_strand):\n",
    "    chrom, strand = chrom_strand\n",
    "    self_genes_sql = pd.read_sql_query(f\"SELECT * FROM human WHERE Feature = 'gene' AND Chromosome = '{chrom}' AND Strand = '{strand}'\", conn)\n",
    "    other_genes = other_genes_all[(other_genes_all[\"Chromosome\"] == chrom) & (other_genes_all[\"Strand\"] == strand)]\n",
    "    overlapping_genes_sql = pr.methods.intersection._overlap(self_genes_sql, other_genes, how=\"first\")\n",
    "    return overlapping_genes_sql\n",
    "\n",
    "def get_overlapping_genes_sql_multi():\n",
    "    chrom_strand_tup = pd.read_sql_query(\"SELECT DISTINCT Chromosome, Strand FROM human\", conn)\n",
    "    chrom_strand_tup = list(zip(chrom_strand_tup[\"Chromosome\"], chrom_strand_tup[\"Strand\"]))\n",
    "    with Pool(8) as p:\n",
    "        overlapping_genes_sql = p.map(get_overlapping_genes_sql, chrom_strand_tup)\n",
    "    overlapping_genes_sql = pd.concat(overlapping_genes_sql) #.sort_values([\"Chromosome\", \"Strand\", \"Start\", \"End\"]).reset_index(drop=True)\n",
    "    return overlapping_genes_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 s ± 190 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time taken to find overlapping genes using sql is 2.29 s ± 190 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "time = get_ipython().run_line_magic(\"timeit\",'-o overlapping_genes_sql = get_overlapping_genes_sql_multi()')\n",
    "results_file.write(f\"Time taken to find overlapping genes using sql is {time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping genes are identical\n"
     ]
    }
   ],
   "source": [
    "# check if overlapping_genes_pr and overlapping_genes_sql are identical\n",
    "overlapping_genes_pr = human_gr[human_gr.Feature == \"gene\"].overlap(pr.from_dict({\"Chromosome\": [\"1\"], \"Start\": [100000], \"End\": [200000], \"Strand\": [\"+\"]}), strandedness=\"same\")\n",
    "overlapping_genes_sql = get_overlapping_genes_sql_multi()\n",
    "overlapping_genes_sql = overlapping_genes_sql.sort_values([\"Chromosome\", \"Strand\", \"Start\", \"End\"]).reset_index(drop=True)\n",
    "overlapping_genes_pr = overlapping_genes_pr.df.sort_values([\"Chromosome\", \"Strand\", \"Start\", \"End\"]).reset_index(drop=True)\n",
    "diff = overlapping_genes_pr.compare(overlapping_genes_sql)\n",
    "if diff.empty:\n",
    "    results_file.write(\"overlapping genes are identical\\n\")\n",
    "else:\n",
    "    results_file.write(\"overlapping genes are not identical\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Subtracting Intervals\n",
    "Remove a set of repetitive regions from the exon features.\n",
    "\n",
    "chr1:15M-16M,20M-21M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38 s ± 74.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # Using pyranges\n",
    "# %timeit subtracted_intervals_pr = human_gr[human_gr.Feature == \"exon\"].merge(strand=False).subtract(pr.from_dict({\"Chromosome\": [\"1\", \"1\"],\"Start\": [15000000, 20000000],\"End\": [16000000, 21000000],}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 28s ± 441 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # using gffutils TODO: run\n",
    "# def subtracted_intervals_gffutls():\n",
    "#     exon_intervals_subtract = pybedtools.BedTool.from_dataframe(pd.DataFrame({\"Chromosome\": [\"1\", \"1\"], \"Start\": [15000000, 20000000], \"End\": [16000000, 21000000]}))\n",
    "#     exon_intervals = [\n",
    "#         gffutils.helpers.asinterval(exon) for exon in human_db.features_of_type(\"exon\")\n",
    "#     ]\n",
    "#     exon_intervals_sorted = sorted(exon_intervals, key=lambda x: (x.chrom, x.start))\n",
    "#     # Use pybedtools to merge overlapping intervals\n",
    "#     return pybedtools.BedTool(exon_intervals_sorted).merge().subtract(exon_intervals_subtract)\n",
    "# %timeit overlapping_genes_gff = overlapping_genes_gffutls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.28 s ± 37.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# # using sql\n",
    "# def find_subtracted_intervals_sql():\n",
    "#     exon_intervals_subtract = pybedtools.BedTool.from_dataframe(pd.DataFrame({\"Chromosome\": [\"1\", \"1\"], \"Start\": [15000000, 20000000], \"End\": [16000000, 21000000]}))\n",
    "#     exon_intervals = pd.read_sql_query(\"SELECT Chromosome, Start, End FROM human WHERE Feature = 'exon' ORDER BY Chromosome, Start\", conn)\n",
    "#     # Use pybedtools to merge overlapping intervals\n",
    "#     return pybedtools.BedTool.from_dataframe(exon_intervals).merge().subtract(exon_intervals_subtract)\n",
    "# %timeit subtracted_intervals_sql = find_subtracted_intervals_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
